{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis_Distributed/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, we use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, we can watch the agent's performance, if it selects an action at random with each time step. A window should pop up that allows us to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the repo, we'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.12399999722838402\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "#     print('state: ' + str(states))\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     print('action: ' + str(actions))\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     print('reward: ' + str(rewards))\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training\n",
    "\n",
    "Now we turn to train our own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n",
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis_Distributed/Reacher.x86_64')\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n",
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [1.88999996 0.48999999 0.26999999 3.57999992 0.56999999 1.67999996\n",
      " 0.41999999 1.55999997 1.25999997 1.15999997 1.51999997 0.76999998\n",
      " 1.07999998 2.87999994 2.00999996 1.27999997 1.06999998 0.71999998\n",
      " 0.16       0.15      ]\t mean score: 1.2259999725967645\n",
      "\n",
      "Episode 1\tAverage Score: 1.23scores: [2.94999993 1.26999997 1.25999997 0.94999998 2.69999994 2.14999995\n",
      " 0.96999998 0.62999999 1.34999997 1.72999996 1.08999998 1.88999996\n",
      " 3.64999992 2.18999995 1.12999997 2.08999995 1.53999997 3.56999992\n",
      " 2.50999994 2.89999994]\t mean score: 1.9259999569505453\n",
      "\n",
      "Episode 2\tAverage Score: 1.58scores: [5.07999989 2.98999993 3.40999992 3.17999993 1.86999996 3.87999991\n",
      " 1.32999997 2.43999995 0.86999998 5.21999988 2.90999993 3.18999993\n",
      " 4.6499999  4.98999989 5.03999989 2.99999993 2.93999993 0.93999998\n",
      " 3.48999992 4.86999989]\t mean score: 3.3144999259151517\n",
      "\n",
      "Episode 3\tAverage Score: 2.16scores: [ 6.51999985  6.83999985  9.63999978  6.50999985  4.92999989  7.56999983\n",
      "  4.91999989  4.4099999   4.71999989  5.01999989 10.39999977  6.88999985\n",
      "  2.96999993  5.67999987  4.90999989  3.33999993  2.21999995  7.23999984\n",
      "  4.2699999   4.03999991]\t mean score: 5.651999873667956\n",
      "\n",
      "Episode 4\tAverage Score: 3.03scores: [ 8.26999982 13.3899997   8.50999981 10.11999977  6.40999986  9.18999979\n",
      "  9.84999978  7.67999983  7.55999983  3.61999992  6.83999985  6.74999985\n",
      "  6.92999985  4.81999989  6.96999984  7.04999984  5.23999988  6.57999985\n",
      "  7.55999983  5.41999988]\t mean score: 7.437999833747744\n",
      "\n",
      "Episode 5\tAverage Score: 3.91scores: [ 8.01999982  9.0099998   5.60999987  5.52999988  9.0499998   7.45999983\n",
      "  9.33999979  6.74999985  6.04999986  7.52999983  9.1699998   2.90999993\n",
      "  9.0599998   7.98999982 11.04999975  6.58999985  6.97999984 12.06999973\n",
      "  4.4999999   5.75999987]\t mean score: 7.521499831881374\n",
      "\n",
      "Episode 6\tAverage Score: 4.51scores: [11.71999974  7.21999984  8.38999981  5.93999987 13.2499997  17.12999962\n",
      " 17.8999996  10.02999978 35.9499992  14.65999967 10.88999976  5.13999989\n",
      " 11.15999975 11.91999973 18.72999958 13.4699997   9.21999979  7.83999982\n",
      " 10.37999977 11.25999975]\t mean score: 12.609999718144536\n",
      "\n",
      "Episode 7\tAverage Score: 5.67scores: [18.48999959  7.33999984 15.82999965 17.9499996  11.24999975 14.04999969\n",
      " 17.34999961 12.46999972 11.19999975 12.68999972 25.89999942  8.10999982\n",
      " 13.88999969 12.83999971 14.20999968 13.04999971 11.34999975 30.72999931\n",
      " 18.20999959  6.09999986]\t mean score: 14.650499672535807\n",
      "\n",
      "Episode 8\tAverage Score: 6.79scores: [22.89999949 28.77999936 12.06999973 15.33999966 17.00999962 23.75999947\n",
      " 16.70999963 13.5999997  25.55999943 25.30999943 13.69999969 15.56999965\n",
      " 23.69999947 12.69999972 26.7799994  14.56999967  9.77999978 13.2099997\n",
      " 18.0899996  17.9099996 ]\t mean score: 18.35249958978966\n",
      "\n",
      "Episode 9\tAverage Score: 8.08scores: [17.8699996  24.02999946 35.13999921 39.52999912 16.83999962 27.73999938\n",
      " 27.86999938 27.69999938 22.5399995  25.03999944 30.76999931 28.50999936\n",
      " 14.53999968 30.55999932 36.50999918 16.25999964 32.34999928 20.34999955\n",
      " 25.28999943 29.56999934]\t mean score: 26.450499408785255\n",
      "\n",
      "Episode 10\tAverage Score: 9.91scores: [30.13999933 33.19999926 25.12999944 33.13999926 28.52999936 22.89999949\n",
      " 33.99999924 25.56999943 19.91999955 15.99999964 22.61999949 34.34999923\n",
      " 34.46999923 26.6799994  34.51999923 25.98999942 27.28999939 32.48999927\n",
      " 27.53999938 31.2199993 ]\t mean score: 28.284999367780983\n",
      "\n",
      "Episode 11\tAverage Score: 11.58scores: [35.28999921 26.7399994  30.33999932 35.39999921 21.76999951 38.52999914\n",
      " 20.80999953 29.24999935 33.34999925 36.35999919 23.21999948 36.46999918\n",
      " 22.62999949 28.20999937 26.7199994  38.47999914 36.31999919 24.31999946\n",
      " 22.13999951 34.53999923]\t mean score: 30.044499328453092\n",
      "\n",
      "Episode 12\tAverage Score: 13.12scores: [32.14999928 36.97999917 33.80999924 35.35999921 18.32999959 18.35999959\n",
      " 35.38999921 37.29999917 35.21999921 38.77999913 29.75999933 38.10999915\n",
      " 30.36999932 29.59999934 35.8099992  36.12999919 19.82999956 31.54999929\n",
      " 34.21999924 30.06999933]\t mean score: 31.85649928795174\n",
      "\n",
      "Episode 13\tAverage Score: 14.56scores: [27.39999939 27.53999938 27.09999939 36.50999918 25.64999943 37.76999916\n",
      " 38.87999913 25.93999942 24.88999944 26.7599994  39.59999911 37.11999917\n",
      " 34.01999924 29.12999935 36.55999918 37.94999915 36.59999918 35.6499992\n",
      " 34.30999923 37.22999917]\t mean score: 32.83049926618114\n",
      "\n",
      "Episode 14\tAverage Score: 15.87scores: [37.38999916 36.18999919 38.00999915 25.68999943 36.37999919 37.11999917\n",
      " 39.10999913 35.6999992  38.37999914 39.49999912 25.58999943 36.41999919\n",
      " 37.00999917 29.92999933 37.29999917 35.8599992  31.4399993  36.74999918\n",
      " 37.68999916 37.61999916]\t mean score: 35.453999207541344\n",
      "\n",
      "Episode 15\tAverage Score: 17.17scores: [37.86999915 39.05999913 38.86999913 32.22999928 37.66999916 38.83999913\n",
      " 38.90999913 37.82999915 29.87999933 30.65999931 32.27999928 37.78999916\n",
      " 39.46999912 37.50999916 32.18999928 39.08999913 36.47999918 39.22999912\n",
      " 38.67999914 38.31999914]\t mean score: 36.64299918096513\n",
      "\n",
      "Episode 16\tAverage Score: 18.39scores: [36.24999919 36.72999918 32.01999928 39.42999912 38.04999915 37.91999915\n",
      " 38.70999913 38.40999914 38.73999913 39.39999912 28.47999936 31.1899993\n",
      " 38.61999914 35.9899992  37.49999916 36.02999919 30.78999931 38.41999914\n",
      " 39.39999912 37.96999915]\t mean score: 36.502499184105545\n",
      "\n",
      "Episode 17\tAverage Score: 19.46scores: [36.31999919 38.34999914 36.61999918 38.57999914 38.40999914 36.59999918\n",
      " 37.02999917 37.39999916 36.53999918 35.17999921 34.19999924 35.51999921\n",
      " 38.87999913 36.31999919 36.34999919 36.86999918 36.73999918 37.11999917\n",
      " 39.46999912 31.93999929]\t mean score: 36.72199917919934\n",
      "\n",
      "Episode 18\tAverage Score: 20.42scores: [37.63999916 35.8499992  37.41999916 37.86999915 37.02999917 33.56999925\n",
      " 37.07999917 38.64999914 39.07999913 38.83999913 38.36999914 38.84999913\n",
      " 39.53999912 38.69999913 37.01999917 38.97999913 36.63999918 38.93999913\n",
      " 39.00999913 39.54999912]\t mean score: 37.9314991521649\n",
      "\n",
      "Episode 19\tAverage Score: 21.34scores: [38.43999914 39.56999912 38.38999914 39.12999913 38.19999915 38.56999914\n",
      " 22.90999949 39.47999912 39.38999912 39.56999912 38.09999915 37.89999915\n",
      " 39.20999912 38.73999913 37.04999917 38.80999913 37.08999917 38.43999914\n",
      " 36.52999918 39.22999912]\t mean score: 37.737499156501144\n",
      "\n",
      "Episode 20\tAverage Score: 22.16scores: [39.04999913 36.35999919 39.09999913 39.25999912 38.83999913 38.59999914\n",
      " 36.85999918 38.28999914 38.02999915 39.41999912 38.95999913 36.35999919\n",
      " 35.7299992  37.95999915 36.01999919 38.42999914 25.67999943 19.98999955\n",
      " 37.00999917 33.27999926]\t mean score: 36.161499191727486\n",
      "\n",
      "Episode 21\tAverage Score: 22.82scores: [39.10999913 37.95999915 38.39999914 38.04999915 39.51999912 38.28999914\n",
      " 38.81999913 34.45999923 33.17999926 38.71999913 36.46999918 38.72999913\n",
      " 39.49999912 38.65999914 39.41999912 37.83999915 39.54999912 33.05999926\n",
      " 38.95999913 39.58999912]\t mean score: 37.914499152544884\n",
      "\n",
      "Episode 22\tAverage Score: 23.51scores: [39.47999912 38.21999915 26.9599994  39.17999912 34.84999922 39.49999912\n",
      " 39.54999912 37.55999916 39.50999912 38.84999913 38.25999914 37.65999916\n",
      " 38.06999915 38.23999915 37.45999916 37.35999916 39.39999912 36.79999918\n",
      " 36.09999919 39.46999912]\t mean score: 37.623999159038064\n",
      "\n",
      "Episode 23\tAverage Score: 24.12scores: [39.45999912 39.44999912 39.50999912 39.41999912 39.05999913 39.49999912\n",
      " 39.45999912 39.55999912 33.21999926 37.93999915 37.46999916 39.42999912\n",
      " 38.85999913 39.41999912 37.62999916 39.41999912 37.86999915 39.05999913\n",
      " 39.48999912 39.46999912]\t mean score: 38.73499913420528\n",
      "\n",
      "Episode 24\tAverage Score: 24.73scores: [39.13999913 38.74999913 37.56999916 30.09999933 39.24999912 39.54999912\n",
      " 39.38999912 36.34999919 39.50999912 28.00999937 39.41999912 30.38999932\n",
      " 37.71999916 36.36999919 39.14999912 39.54999912 39.40999912 37.30999917\n",
      " 31.61999929 37.57999916]\t mean score: 36.80699917729944\n",
      "\n",
      "Episode 25\tAverage Score: 25.22scores: [37.74999916 39.55999912 39.00999913 36.16999919 39.50999912 38.55999914\n",
      " 39.03999913 38.80999913 39.53999912 33.69999925 37.67999916 38.15999915\n",
      " 38.74999913 38.18999915 39.53999912 38.44999914 38.78999913 38.41999914\n",
      " 39.39999912 37.86999915]\t mean score: 38.34499914292246\n",
      "\n",
      "Episode 26\tAverage Score: 25.72scores: [36.99999917 38.85999913 39.18999912 35.35999921 39.20999912 38.98999913\n",
      " 39.24999912 34.05999924 39.53999912 39.03999913 39.51999912 36.71999918\n",
      " 34.23999923 34.76999922 38.12999915 38.17999915 37.89999915 39.39999912\n",
      " 39.43999912 39.55999912]\t mean score: 37.917999152466656\n",
      "\n",
      "Episode 27\tAverage Score: 26.17scores: [38.89999913 36.60999918 38.27999914 39.57999912 39.31999912 39.05999913\n",
      " 38.20999915 39.40999912 39.37999912 37.54999916 34.73999922 38.20999915\n",
      " 38.71999913 36.16999919 38.79999913 39.08999913 31.05999931 39.14999912\n",
      " 38.88999913 38.83999913]\t mean score: 37.99849915066734\n",
      "\n",
      "Episode 28\tAverage Score: 26.59scores: [39.18999912 38.90999913 36.23999919 37.05999917 38.05999915 36.96999917\n",
      " 38.62999914 38.67999914 37.59999916 38.12999915 31.07999931 37.64999916\n",
      " 37.92999915 39.23999912 38.78999913 38.19999915 38.29999914 33.47999925\n",
      " 37.87999915 38.58999914]\t mean score: 37.530499161127956\n",
      "\n",
      "Episode 29\tAverage Score: 26.97scores: [39.13999913 38.58999914 37.76999916 37.62999916 38.82999913 37.52999916\n",
      " 38.57999914 39.07999913 38.95999913 38.49999914 39.35999912 35.54999921\n",
      " 37.59999916 37.95999915 39.19999912 37.77999916 39.18999912 39.45999912\n",
      " 38.85999913 34.72999922]\t mean score: 38.21499914582819\n",
      "\n",
      "Episode 30\tAverage Score: 27.35scores: [39.31999912 37.43999916 36.95999917 38.98999913 39.21999912 39.32999912\n",
      " 39.45999912 36.08999919 34.77999922 38.55999914 39.07999913 38.44999914\n",
      " 25.26999944 39.13999913 39.63999911 39.28999912 39.20999912 36.95999917\n",
      " 39.04999913 38.37999914]\t mean score: 37.73099915664643\n",
      "\n",
      "Episode 31\tAverage Score: 27.68scores: [39.41999912 35.9099992  38.73999913 36.48999918 39.54999912 36.83999918\n",
      " 38.94999913 38.59999914 34.99999922 39.58999912 34.73999922 36.03999919\n",
      " 37.15999917 39.48999912 35.41999921 39.60999911 39.57999912 35.6799992\n",
      " 38.65999914 39.06999913]\t mean score: 37.726999156735836\n",
      "\n",
      "Episode 32\tAverage Score: 28.00scores: [35.9699992  39.03999913 37.76999916 33.62999925 39.36999912 36.88999918\n",
      " 37.70999916 39.53999912 33.53999925 38.52999914 36.90999917 39.39999912\n",
      " 39.30999912 38.87999913 39.50999912 38.85999913 37.84999915 39.14999912\n",
      " 38.61999914 38.81999913]\t mean score: 37.96499915141612\n",
      "\n",
      "Episode 33\tAverage Score: 28.30scores: [39.46999912 37.22999917 38.26999914 37.43999916 38.48999914 38.58999914\n",
      " 39.34999912 39.21999912 39.02999913 39.26999912 39.58999912 39.56999912\n",
      " 39.40999912 38.86999913 39.08999913 39.09999913 38.85999913 39.38999912\n",
      " 39.46999912 39.34999912]\t mean score: 38.9529991293326\n",
      "\n",
      "Episode 34\tAverage Score: 28.61scores: [39.20999912 37.76999916 39.46999912 38.69999913 24.01999946 39.56999912\n",
      " 34.69999922 39.18999912 37.55999916 35.08999922 37.78999916 39.20999912\n",
      " 37.50999916 39.07999913 38.76999913 39.31999912 38.21999915 39.47999912\n",
      " 39.28999912 36.46999918]\t mean score: 37.5209991613403\n",
      "\n",
      "Episode 35\tAverage Score: 28.87scores: [28.98999935 39.31999912 33.94999924 39.12999913 39.08999913 34.84999922\n",
      " 36.38999919 39.52999912 38.53999914 39.07999913 38.55999914 38.90999913\n",
      " 38.89999913 39.11999913 39.07999913 39.57999912 39.35999912 39.36999912\n",
      " 36.09999919 38.31999914]\t mean score: 37.80849915491417\n",
      "\n",
      "Episode 36\tAverage Score: 29.11scores: [38.18999915 38.38999914 38.19999915 38.94999913 39.15999912 39.02999913\n",
      " 38.11999915 37.86999915 39.53999912 38.65999914 38.78999913 38.30999914\n",
      " 39.06999913 37.57999916 38.81999913 37.11999917 38.85999913 39.47999912\n",
      " 38.84999913 38.55999914]\t mean score: 38.57749913772568\n",
      "\n",
      "Episode 37\tAverage Score: 29.37scores: [39.46999912 39.37999912 39.57999912 38.48999914 39.61999911 38.67999914\n",
      " 37.48999916 38.99999913 39.51999912 39.56999912 38.95999913 39.59999911\n",
      " 39.50999912 39.55999912 39.50999912 39.09999913 39.32999912 39.24999912\n",
      " 38.94999913 39.49999912]\t mean score: 39.20349912373349\n",
      "\n",
      "Episode 38\tAverage Score: 29.63scores: [38.40999914 38.69999913 39.42999912 39.13999913 39.34999912 37.91999915\n",
      " 39.29999912 35.9499992  38.99999913 33.97999924 35.17999921 39.51999912\n",
      " 39.13999913 38.95999913 39.26999912 39.53999912 38.31999914 39.57999912\n",
      " 39.13999913 39.29999912]\t mean score: 38.45649914043024\n",
      "\n",
      "Episode 39\tAverage Score: 29.85scores: [35.52999921 39.50999912 38.76999913 37.87999915 37.98999915 38.94999913\n",
      " 39.35999912 38.32999914 39.24999912 36.98999917 38.21999915 39.19999912\n",
      " 38.97999913 39.54999912 35.7099992  39.46999912 39.52999912 39.42999912\n",
      " 39.49999912 39.36999912]\t mean score: 38.57599913775921\n",
      "\n",
      "Episode 40\tAverage Score: 30.07Environment Solved. Episode40. Average Score: 30.07.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ddpg_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=0)\n",
    "\n",
    "def ddpg(n_episodes=1000, max_t=1000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        states = env.reset(train_mode=True)[brain_name].vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations      # get the next states\n",
    "            rewards = env_info.rewards                      # get the rewards\n",
    "            dones = env_info.local_done                     # see if episodes has finished\n",
    "            \n",
    "            # Take a step for each 'agent'\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "                \n",
    "            states = next_states\n",
    "            score += rewards\n",
    "\n",
    "        print('scores: ' + str(score) + '\\t mean score: ' + str(score.mean()) + '\\n') \n",
    "\n",
    "        scores_deque.append(score.mean())\n",
    "        scores.append(score.mean())\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "        if np.mean(scores_deque) > 30:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('Environment Solved. Episode{}. Average Score: {:.2f}.'.format(i_episode, np.mean(scores_deque)))\n",
    "            break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis_Distributed/Reacher.x86_64')\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1\tAverage Score: 1.29\n",
      "\n",
      "Episode 2\tAverage Score: 4.29\n",
      "\n",
      "Episode 3\tAverage Score: 9.63\n",
      "\n",
      "Episode 4\tAverage Score: 12.48\n",
      "\n",
      "Episode 5\tAverage Score: 16.93\n",
      "\n",
      "Episode 6\tAverage Score: 22.45\n",
      "\n",
      "Episode 7\tAverage Score: 31.10\n",
      "\n",
      "Episode 8\tAverage Score: 32.43\n",
      "\n",
      "Episode 9\tAverage Score: 33.44\n",
      "\n",
      "Episode 10\tAverage Score: 32.19\n",
      "\n",
      "Episode 11\tAverage Score: 34.81\n",
      "\n",
      "Episode 12\tAverage Score: 34.06\n",
      "\n",
      "Episode 13\tAverage Score: 34.27\n",
      "\n",
      "Episode 14\tAverage Score: 34.03\n",
      "\n",
      "Episode 15\tAverage Score: 35.20\n",
      "\n",
      "Episode 16\tAverage Score: 34.49\n",
      "\n",
      "Episode 17\tAverage Score: 34.37\n",
      "\n",
      "Episode 18\tAverage Score: 34.32\n",
      "\n",
      "Episode 19\tAverage Score: 35.88\n",
      "\n",
      "Episode 20\tAverage Score: 32.60\n",
      "\n",
      "Episode 21\tAverage Score: 34.88\n",
      "\n",
      "Episode 22\tAverage Score: 33.28\n",
      "\n",
      "Episode 23\tAverage Score: 34.99\n",
      "\n",
      "Episode 24\tAverage Score: 35.83\n",
      "\n",
      "Episode 25\tAverage Score: 35.48\n",
      "\n",
      "Episode 26\tAverage Score: 32.56\n",
      "\n",
      "Episode 27\tAverage Score: 32.05\n",
      "\n",
      "Episode 28\tAverage Score: 35.36\n",
      "\n",
      "Episode 29\tAverage Score: 32.60\n",
      "\n",
      "Episode 30\tAverage Score: 33.55\n",
      "\n",
      "Episode 31\tAverage Score: 34.92\n",
      "\n",
      "Episode 32\tAverage Score: 35.61\n",
      "\n",
      "Episode 33\tAverage Score: 33.19\n",
      "\n",
      "Episode 34\tAverage Score: 32.86\n",
      "\n",
      "Episode 35\tAverage Score: 35.01\n",
      "\n",
      "Episode 36\tAverage Score: 33.54\n",
      "\n",
      "Episode 37\tAverage Score: 35.36\n",
      "\n",
      "Episode 38\tAverage Score: 35.45\n",
      "\n",
      "Episode 39\tAverage Score: 36.18\n",
      "\n",
      "Episode 40\tAverage Score: 33.99\n",
      "\n",
      "Episode 41\tAverage Score: 36.45\n",
      "\n",
      "Episode 42\tAverage Score: 34.37\n",
      "\n",
      "Episode 43\tAverage Score: 37.82\n",
      "\n",
      "Episode 44\tAverage Score: 36.77\n",
      "\n",
      "Episode 45\tAverage Score: 37.46\n",
      "\n",
      "Episode 46\tAverage Score: 36.55\n",
      "\n",
      "Episode 47\tAverage Score: 37.65\n",
      "\n",
      "Episode 48\tAverage Score: 34.84\n",
      "\n",
      "Episode 49\tAverage Score: 36.64\n",
      "\n",
      "Episode 50\tAverage Score: 36.64\n",
      "\n",
      "Episode 51\tAverage Score: 36.81\n",
      "\n",
      "Episode 52\tAverage Score: 36.49\n",
      "\n",
      "Episode 53\tAverage Score: 31.01\n",
      "\n",
      "Episode 54\tAverage Score: 26.63\n",
      "\n",
      "Episode 55\tAverage Score: 21.84\n",
      "\n",
      "Episode 56\tAverage Score: 22.39\n",
      "\n",
      "Episode 57\tAverage Score: 24.18\n",
      "\n",
      "Episode 58\tAverage Score: 29.36\n",
      "\n",
      "Episode 59\tAverage Score: 29.26\n",
      "\n",
      "Episode 60\tAverage Score: 29.53\n",
      "\n",
      "Episode 61\tAverage Score: 25.09\n",
      "\n",
      "Episode 62\tAverage Score: 28.53\n",
      "\n",
      "Episode 63\tAverage Score: 32.31\n",
      "\n",
      "Episode 64\tAverage Score: 30.23\n",
      "\n",
      "Episode 65\tAverage Score: 35.04\n",
      "\n",
      "Episode 66\tAverage Score: 31.79\n",
      "\n",
      "Episode 67\tAverage Score: 33.56\n",
      "\n",
      "Episode 68\tAverage Score: 33.92\n",
      "\n",
      "Episode 69\tAverage Score: 36.27\n",
      "\n",
      "Episode 70\tAverage Score: 34.83\n",
      "\n",
      "Episode 71\tAverage Score: 33.84\n",
      "\n",
      "Episode 72\tAverage Score: 32.73\n",
      "\n",
      "Episode 73\tAverage Score: 32.49\n",
      "\n",
      "Episode 74\tAverage Score: 29.36\n",
      "\n",
      "Episode 75\tAverage Score: 33.72\n",
      "\n",
      "Episode 76\tAverage Score: 35.94\n",
      "\n",
      "Episode 77\tAverage Score: 36.21\n",
      "\n",
      "Episode 78\tAverage Score: 34.02\n",
      "\n",
      "Episode 79\tAverage Score: 36.17\n",
      "\n",
      "Episode 80\tAverage Score: 33.37\n",
      "\n",
      "Episode 81\tAverage Score: 34.47\n",
      "\n",
      "Episode 82\tAverage Score: 32.42\n",
      "\n",
      "Episode 83\tAverage Score: 32.70\n",
      "\n",
      "Episode 84\tAverage Score: 31.25\n",
      "\n",
      "Episode 85\tAverage Score: 35.05\n",
      "\n",
      "Episode 86\tAverage Score: 37.17\n",
      "\n",
      "Episode 87\tAverage Score: 37.22\n",
      "\n",
      "Episode 88\tAverage Score: 37.32\n",
      "\n",
      "Episode 89\tAverage Score: 38.13\n",
      "\n",
      "Episode 90\tAverage Score: 35.46\n",
      "\n",
      "Episode 91\tAverage Score: 32.15\n",
      "\n",
      "Episode 92\tAverage Score: 34.04\n",
      "\n",
      "Episode 93\tAverage Score: 32.07\n",
      "\n",
      "Episode 94\tAverage Score: 35.19\n",
      "\n",
      "Episode 95\tAverage Score: 35.38\n",
      "\n",
      "Episode 96\tAverage Score: 35.37\n",
      "\n",
      "Episode 97\tAverage Score: 32.07\n",
      "\n",
      "Episode 98\tAverage Score: 30.98\n",
      "\n",
      "Episode 99\tAverage Score: 33.04\n",
      "\n",
      "Episode 100\tAverage Score: 33.39\n",
      "\n",
      "Environment Solved. Episode100. Average Score: 33.39.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ddpg_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=0)\n",
    "\n",
    "def ddpg(n_episodes=1000, max_t=1000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        states = env.reset(train_mode=True)[brain_name].vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations      # get the next states\n",
    "            rewards = env_info.rewards                      # get the rewards\n",
    "            dones = env_info.local_done                     # see if episodes has finished\n",
    "            \n",
    "            # Take a step for each 'agent'\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "                \n",
    "            states = next_states\n",
    "            score += rewards\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break\n",
    "\n",
    "#         print('scores: ' + str(score) + '\\t mean score: ' + str(score.mean()) + '\\n') \n",
    "\n",
    "        scores_deque.append(score.mean())\n",
    "        scores.append(score.mean())\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\nEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "        if np.mean(scores_deque) > 30 and i_episode >= 100:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print()\n",
    "            print('Environment Solved. Episode{}. Average Score: {:.2f}.'.format(i_episode, np.mean(scores_deque)))\n",
    "            break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = ddpg(print_every=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.23950927939079"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the enviroment is solved since above has print out every 1 instead of 100\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Network and Hyperparameters\n",
    "\n",
    "The network is an Actor-Critic architecture and hyperparameters used to train are as follows:\n",
    "\n",
    "- Replay Buffer Size = 1M\n",
    "- Batch Size = 256\n",
    "- Optimizer: Adam\n",
    "- Learning Rate (Actor) = 1 x 10^-4\n",
    "- Learning Rate (Critic) = 1 x 10^-3\n",
    "- Tau = 1 x 10^-3\n",
    "- Gamma = 0.99\n",
    "- Noise decay rate = 0.9999\n",
    "- Minimum epsilon value = 0.01\n",
    "- Update frequency is every 20 steps\n",
    "- Learning passes every update is 20 times.\n",
    "- Number of Agents: 20\n",
    "- Gradient Clipping was used.\n",
    "\n",
    "Noise Process:\n",
    "\n",
    "I've used a different Ornstein–Uhlenbeck noise process for each agent that is normally distributed with parameters sampled from a uniform distribution where:\n",
    "\n",
    "- $\\mu$ = 0\n",
    "- $\\sigma$ ~ [0.1, 0.30]\n",
    "- $\\theta$ ~ [0.10, 0.20]\n",
    "\n",
    "Network:\n",
    "\n",
    "Actor: MLP\n",
    "- Input Layer: 33 neurons\n",
    "- Layer 1: 400 neurons\n",
    "- Layer 2: 300 neurons\n",
    "- Output Layer: 4 neurons\n",
    "\n",
    "Critic: MLP\n",
    "- Input Layer: 37 neurons\n",
    "- Layer 1: 400 neurons\n",
    "- Layer 2: 300 neurons\n",
    "- Output Layer: 1 Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load and run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "state = env.reset()\n",
    "for t in range(200):\n",
    "    action = agent.act(state, add_noise=False)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Future work\n",
    "\n",
    "1. Try out different algorithms:\n",
    "- TRPO\n",
    "- TNPG\n",
    "- PPO\n",
    "- D4PG\n",
    "2. Try solving the Crawler environment\n",
    "3. Implement adding noise to the parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
